# Evaluaci√≥n de Retenci√≥n Sem√°ntica mediante Preguntas Tipo Test ‚Äî GPT-4

Este m√≥dulo contiene los scripts necesarios para generar, transformar y evaluar autom√°ticamente preguntas tipo test utilizando textos procesados por el modelo GPT-4 Mini. Se trata de una parte del proyecto de evaluaci√≥n iterativa de modelos de lenguaje, centrada en medir la fidelidad sem√°ntica y de comprensi√≥n tras cada iteraci√≥n de resumen y expansi√≥n.

---

## üß† Objetivo

Evaluar la capacidad de comprensi√≥n de GPT-4 Mini sobre versiones modificadas de textos (originales, resumidos, expandidos) mediante generaci√≥n y resoluci√≥n automatizada de tests.

---

## üìÇ Estructura de archivos

### Scripts incluidos

- `generaci√≥n_preguntas_test_gpt4.py`: genera preguntas de opci√≥n m√∫ltiple a partir de textos usando GPT-4 Mini mediante API.
- `json_output_to_excel_gpt4.py`: transforma las respuestas generadas (en formato JSONL) a Excel estructurado.
- `answer_input_gpt4.py`: genera el archivo JSONL con combinaciones de preguntas + textos para evaluar.
- `answer_gpt4_output.py`: eval√∫a las respuestas del modelo sobre textos modificados y almacena resultados.

---

## üìÅ Archivos de datos

Debido al tama√±o de los ficheros (`.jsonl` y `.xlsx`), estos no est√°n en este repositorio. Puedes encontrarlos en el siguiente enlace de Google Drive:

üìé [Google Drive - Archivos GPT-4](https://drive.google.com/drive/folders/1Ox28iNqlJ3ftdcZLCcHMAQPfhQtW-zZ8)

Incluyen:
- `questions_output_1000.xlsx`: Preguntas generadas desde el texto original.
- `output_gpt4-mini_1000.xlsx`: Textos procesados con GPT-4 Mini.
- `benchmark_input_answer_gpt4.jsonl`: Benchmark de entrada para evaluaci√≥n.
- `answers_gpt4_output.jsonl`: Respuestas del modelo a las preguntas.
- `questions_transformadas_gpt4.xlsx`: Preguntas en formato tabular para evaluaci√≥n.

---

## ‚ñ∂Ô∏è Uso b√°sico

1. **Generar preguntas**:
   ```bash
   python generaci√≥n_preguntas_test_gpt4.py
   ```

2. **Convertir a Excel**:
   ```bash
   python json_output_to_excel_gpt4.py
   ```

3. **Preparar benchmark**:
   ```bash
   python answer_input_gpt4.py
   ```

4. **Evaluar respuestas**:
   ```bash
   python answer_gpt4_output.py
   ```

---

## üìÑ Licencia

MIT License ‚Äî libre para uso, distribuci√≥n y modificaci√≥n con atribuci√≥n.

---

## ‚úçÔ∏è Autor

Javier Gonz√°lez P√©rez  
[Repositorio principal del TFG](https://github.com/JAVIERTEL/TFG)